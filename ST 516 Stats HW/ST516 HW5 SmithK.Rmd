---
title: 'ST516 Homework #5'
author: "Keenan T. Smith"
output: 
  html_document:
    theme:
      bootswatch: pulse
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

"Built with R Version `r getRversion()`"

Links Used:
<https://www.learnbymarketing.com/tutorials/explaining-the-lm-summary-in-r/>
<https://rpubs.com/aaronsc32/regression-confidence-prediction-intervals>

```{r Library Initiate, include=FALSE}
library(tidyverse)
library(lubridate)
```

### Problem #1
```{r}
xi <- 89457
yi <- 340725
yi2 <- 8451966400
b1 <- -1.774
xyi <- 2146561000
n1 <- 14

b0 <- (yi / n1) - b1 * (xi / n1)

SSE <- yi2 - b0 * yi - b1 * xyi

SSE

Se <- sqrt(SSE / (n1 - 2))
Se
```

### Problem #2
```{r}
# Import Data
movies <- read_csv("data/King Kong.csv")

movies <- movies %>%
  rename(budget = `Budget($mill)`, gross = `USGross($mill)`)

movies %>%
  transmute(Movie = Movie, budget = budget, gross = gross, difference = gross - budget) %>%
  arrange(difference)

lm_fit_movies <- lm(gross ~ budget, data = movies)

summary(lm_fit_movies)

ggplot(movies, aes(x = budget, y = gross)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

### Problem #3
```{r}
# Import Data
report_cards <- read_csv("data/wake county schools report card 2015-16.csv")

report_cards %>%
  arrange(desc(GRADELEVEL), desc(LUNCH))
# report_cards

cor(report_cards$LUNCH, report_cards$GRADELEVEL)
cov(report_cards$LUNCH, report_cards$GRADELEVEL)
# Create Prediction Dataframe
report_predict <- tibble(LUNCH = 45)
# report_predict

lm_fit_report <- lm(GRADELEVEL ~ LUNCH, data = report_cards)

summary(lm_fit_report)

lm_var <- lm_fit_report$coefficients

# Amount Decreased Per 15% Rise
fifteen_or_less <- lm_var[2] * 15
fifteen_or_less

ggplot(report_cards, aes(x = LUNCH, y = GRADELEVEL)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)

objects(lm_fit_report)

plot(lm_fit_report)
```

### Problem #4
```{r}
# Import Data
ice <- read_csv("data/nenana ice breakup.csv")

year_2021 <- 2021
year_2021 <- ymd(year_2021, truncated = 2L)

ice_modified <- ice %>%
  select(-c(`...5`, `...6`)) %>%
  rename(starting_year = `Year (since 1900)`, day_number = `Day Number`) %>%
  mutate(year_start = ymd(Year, truncated = 2L), date_total = as_datetime(year_start + day_number)) %>%
  filter(Year != 2021)

ice_modified

prediction <- tibble(starting_year = 121)

lm_fit_ice <- lm(day_number ~ starting_year, data = ice_modified)

summary(lm_fit_ice)

prediction_2021 <- predict(lm_fit_ice, newdata = prediction)
prediction_asdate <- as_datetime(year_2021 + prediction_2021)
prediction_asdate

prediction_tibble <- tibble(Year = 2021, starting_year = 121, day_number = prediction_2021)
prediction_tibble <-
  prediction_tibble %>%
  mutate(year_start = ymd(Year, truncated = 2L), date_total = as_datetime(year_start + day_number))

actual_tibble <- ice %>%
  select(-c(`...5`, `...6`)) %>%
  rename(starting_year = `Year (since 1900)`, day_number = `Day Number`) %>%
  mutate(year_start = ymd(Year, truncated = 2L), date_total = as_datetime(year_start + day_number)) %>%
  filter(Year == 2021)

prediction_time <- pull(prediction_tibble, date_total)
actual_time <- pull(actual_tibble, date_total)

difference_time <- prediction_time - actual_time
difference_time <- as.duration(difference_time)

ggplot(ice_modified, aes(x = starting_year, y = day_number)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

### Problem #5
```{r}
college_access <- read_csv("data/College Access Index.csv")

college_access_modified <-
  college_access %>%
  rename(
    college = `College`,
    pell_2012_2014 = `Pell (2012-2014)`,
    pell_2008 = `Pell (2008)`,
    pell_change = `Pell change`,
    low_to_middle = `Net price, low- to middle-income`,
    college_access_index = `College Access Index`,
    endowment_per_student = `Endowment per student`
  ) %>%
  mutate(row = row_number())

summary(college_access_modified)

mean_low_to_middle <- mean(college_access_modified$low_to_middle)

duke <-
  college_access_modified %>%
  filter(college == "Duke")

lm_fit_college_access <- lm(low_to_middle ~ college_access_index, data = college_access_modified)

summary(lm_fit_college_access)

residuals_ca <- tibble(residuals = lm_fit_college_access$residuals)

college_access_modified <-
  college_access_modified %>%
  bind_cols(residuals_ca)

college_access_modified

ggplot(college_access_modified, aes(x = college_access_index, y = low_to_middle)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

### Problem #6
```{r}
reptile <- read_csv("data/REPTILE BRAIN BODY WEIGHTS.csv")
mammal <- read_csv("data/mammals brain body mass.csv")

reptile_modified <-
  reptile %>%
  rename(
    species = Species,
    body_mass = `Body mass (kg)`,
    brain_mass = `Brain mass (g)`,
    log_body_mass = `Log10 Body mass (kg)`,
    log_brain_mass = `Log10 Brain mass (g)`
  ) %>%
  mutate(row = row_number())

mammal_modified <-
  mammal %>%
  rename(
    species = Species,
    body_mass = `Body mass(kg)`,
    brain_mass = `Brain mass (g)`,
    log_body_mass = `log(10)Body mass (kg)`,
    log_brain_mass = `log(10)Brain mass (g)`
  ) %>%
  mutate(row = row_number())

lm_fit_reptile <- lm(log_brain_mass ~ log_body_mass, data = reptile_modified)
lm_fit_mammal <- lm(log_brain_mass ~ log_body_mass, data = mammal_modified)

king_kong <- tibble(species = "King Kong", body_mass = 140)
king_kong <- king_kong %>% mutate(log_body_mass = log10(body_mass))
godzilla <- tibble(species = "Godzilla", body_mass = 180)
godzilla <- godzilla %>% mutate(log_body_mass = log10(body_mass))
prediction_king_kong <- predict(lm_fit_mammal, newdata = king_kong)
prediction_godzilla <- predict(lm_fit_reptile, newdata = godzilla)

log_king_kong <- as.numeric(prediction_king_kong)
log_godzilla <- as.numeric(prediction_godzilla)

king_kong_brain_size <- 10^log_king_kong
godzilla_brain_size <- 10^log_godzilla

summary(lm_fit_mammal)
summary(lm_fit_reptile)
```

### Problem #7
```{r}
beer <- read_csv("data/beer_BAC.csv")

ggplot(beer, aes(x = Beers, y = BAC)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)

lm_fit_beer <- lm(BAC ~ Beers, data = beer)
summary(lm_fit_beer)
plot(lm_fit_beer)

tstat_p5 <- abs(qt(.05, df = 14))
# Residual Standard error (Like Standard Deviation)
k <- length(lm_fit_beer$coefficients) - 1 # Subtract one to ignore intercept
SSE <- sum(lm_fit_beer$residuals**2)
n <- length(lm_fit_beer$residuals)
Se <- sqrt(SSE / (n - (1 + k))) # Residual Standard Error
# Standard Deviation of Predictor
Sx <- sd(beer$Beers)
# Standard Deviation of Beta 1
Sb1 <- Se / (sqrt(n - 1) * Sx) # Standard Deviation of Predictor in Model
# Multiple R-Squared (Coefficient of Determination)
SSyy <- sum((beer$BAC - mean(beer$BAC))**2)
SSE <- sum(lm_fit_beer$residuals**2)
(SSyy - SSE) / SSyy
# Adjusted R-Squared
1 - (SSE / SSyy) * (n - 1) / (n - (k + 1))
```

### Problem #8 
<https://rpubs.com/aaronsc32/regression-confidence-prediction-intervals>
```{r}
bodyfat <- read_csv("data/bodyfat.csv")

bodyfat_modified <-
  bodyfat %>%
  rename(
    waist = `Waist (in.)`,
    weight = `Weight (lb)`,
    body_fat = `Body Fat (%)`
  )
bodyfat_modified

lm_fit_bodyfat <- lm(body_fat ~ waist, data = bodyfat_modified)
summary(lm_fit_bodyfat)

prediction_waist <- tibble(waist = 40)
# Confidence Intervals for Beta 1 slope
confint(lm_fit_bodyfat, level = 0.90)
# Confidence Interval for predicted 40 in waist
predict(lm_fit_bodyfat, newdata = prediction_waist, interval = "confidence")
# Prediction Interval for predicted 40 in Waist
predict(lm_fit_bodyfat, newdata = prediction_waist, interval = "prediction")
```

### Problem #9
```{r}
votes <- read_csv("data/Votes.csv")
votes

votes_no_palm_beach <-
  votes %>%
  filter(COUNTY != "Palm Beach" & COUNTY != "TOTAL")

lm_fit_votes <- lm(Buchanan ~ Gore, data = votes_no_palm_beach)
lm_fit_votes$coefficients[2] * 10000
summary(lm_fit_votes)

cor(votes_no_palm_beach$Gore, votes_no_palm_beach$Buchanan)
prediction_gore <- tibble(Gore = 268945)
predict(lm_fit_votes, newdata = prediction_gore, interval = "prediction", level = .99)
```

### Problem #10
```{r}
teams <- read_csv("data/top 50 metro area by pop inc pop percapinc profranch.csv")

teams_modified <-
  teams %>%
  rename(
    rank = Rank,
    metro_geoname = `Metro GeoName`,
    personal_income = `Total Metro Personal Income 2020 (000s)`,
    per_capita = `Per Capita Personal Income 2020`,
    population_mil = `Population 2020 (millions)`,
    num_teams = `# of NFL, NBA, MLB, NHL teams`
  )

teams_modified

lm_fit_teams <- lm(num_teams ~ population_mil, data = teams_modified)
summary(lm_fit_teams)

# Residual Standard error (Like Standard Deviation)
k <- length(lm_fit_teams$coefficients) - 1 # Subtract one to ignore intercept
SSE <- sum(lm_fit_teams$residuals**2)
SSE
n <- length(lm_fit_teams$residuals)
Se <- sqrt(SSE / (n - (1 + k))) # Residual Standard Error
Se
# Standard Deviation of Predictor
Sx <- sd(teams_modified$population_mil)
Sx
# Standard Deviation of Beta 1
Sb1 <- Se / (sqrt(n - 1) * Sx) # Standard Deviation of Predictor in Model
Sb1
# Multiple R-Squared (Coefficient of Determination)
SSyy <- sum((teams_modified$num_teams - mean(teams_modified$num_teams))**2)
SSE <- sum(lm_fit_beer$residuals**2)
(SSyy - SSE) / SSyy
# Adjusted R-Squared
1 - (SSE / SSyy) * (n - 1) / (n - (k + 1))

tstat_p10 <- abs(qt(.05, df = 48))
tstat_p10

confint(lm_fit_teams, level = 0.90)

teams_intercepts <- as.numeric(lm_fit_teams$coefficients[1])
teams_slope <- as.numeric(lm_fit_teams$coefficients[2])

teams_one <-
  teams_modified %>%
  filter(num_teams == 1)
teams_one

mean_one_team <- mean(teams_one$population_mil)

second_team <- 2

one_team <- 1

one_teams <- (one_team - teams_intercepts) / teams_slope

two_teams <- (second_team - teams_intercepts) / teams_slope

two_teams - one_teams

ggplot(teams_modified, aes(x = population_mil, y = num_teams)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  scale_x_continuous(breaks = seq(0, 20, by = 1)) +
  scale_y_continuous(breaks = seq(0, 10, by = 1))

teams_modified %>%
  arrange(num_teams, desc(population_mil)) %>%
  filter(num_teams == 4)
```

### Problem #11
```{r}
satact <- read_csv("data/SAT_ACT.csv")
satact <-
  satact %>%
  filter(!is.na(SAT))
satact

lm_model_testing <- lm(ACT ~ SAT, data = satact)
summary(lm_model_testing)

prediction_act <- satact %>%
  select(-ACT)

ggplot(satact, aes(x = SAT, y = ACT)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)

mean_act <- mean(satact$ACT)
mean_act
sd_act <- sd(satact$ACT)
sd_act

predicted_act <- tibble(predicted = predict(lm_model_testing, newdata = prediction_act))
prediction_act <-
  prediction_act %>%
  bind_cols(predicted_act)

prediction_act

mean_pred_act <- mean(prediction_act$predicted)
mean_pred_act
sd_pred_act <- sd(prediction_act$predicted)
sd_pred_act

ratio_sd <- sd_pred_act / sd_act
ratio_sd

cor(satact$SAT, satact$ACT)

# Question 5
sd_sat <- sd(satact$SAT)
mean_sat <- mean(satact$SAT)

test_sat_score <- 1 * sd_sat + mean_sat

test_sat_score_tib <- tibble(SAT = test_sat_score)

pred_act_1 <- predict(lm_model_testing, newdata = test_sat_score_tib)

z_score_1 <- (pred_act_1 - mean_act) / sd_act
z_score_1

test_stat_1below <- -1 * sd_sat + mean_sat
test_stat_1below
test_stat_1below_tib <- tibble(SAT = test_stat_1below)
pred_act_1below <- predict(lm_model_testing, newdata = test_stat_1below_tib)
pred_act_1below
z_score_2 <- (pred_act_1below - mean_act) / sd_act
z_score_2
```

### Problem #12
```{r}
blood <- read_csv("data/blood test human age.csv")

blood_mod <-
  blood %>%
  rename(
    blood_test = `Blood Test Measure`,
    age = `Age in Years`
  )
blood_mod

lm_fit_blood <- lm(age ~ blood_test, data = blood_mod)
summary(lm_fit_blood)

pred_blood <- tibble(blood_test = -14.2)

predict(lm_fit_blood, newdata = pred_blood, interval = "prediction")
```

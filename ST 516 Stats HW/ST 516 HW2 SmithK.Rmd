---
title: 'ST 516 Homework #2'
author: "Keenan Smith"
output: 
  html_document:
    theme:
      bootswatch: pulse
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

"Built with R Version `r getRversion()`"

```{r Library Initiate, include=FALSE}
library(dplyr)
library(readr)
```


### Problem #1
Use T-Distribution to Determine Confidence Intervals
```{r}
speed <- c(24, 29, 23, 25, 24, 33, 26, 24, 29, 27, 26, 22, 32, 24, 21, 19, 29, 31, 26, 29, 31, 16)
speed_means <- mean(speed)
speed_sd <- sd(speed)
num_obs <- length(speed)
# Normal Distribution Confidence Intervals
error <- qnorm(0.975) * speed_sd / sqrt(num_obs)
left_norm <- speed_means - error
right_norm <- speed_means + error
# T-Distribution Confidence Intervals
error_t <- qt(0.975, df = num_obs - 1) * speed_sd / sqrt(num_obs)
left_t <- speed_means - error_t
right_t <- speed_means + error_t

left_t
right_t
# Plots
hist(speed)
```

### Problem #3
```{r}
textbook_costs <- c(500, 650, 600, 505, 450, 550, 515, 495, 650, 395)
textbook_mean <- mean(textbook_costs)
textbook_sd <- sd(textbook_costs)
textbook_obs <- length(textbook_costs)
# Calculated T-Statistic for Dataset
textbook_t <- (textbook_mean - 500) / (textbook_sd / sqrt(textbook_obs))
textbook_t

# T-Test for Data Set. One for One-Tailed and Another for Two
textbook_t_test <- t.test(textbook_costs, mu = 500, alternative = "greater")
textbook_t_test_2 <- t.test(textbook_costs, mu = 500)

textbook_t_test
textbook_t_test_2

# T-Distribution for Confidence Intervals
error_t_textbooks <- qt(0.975, df = textbook_obs - 1) * textbook_sd / sqrt(textbook_obs)
left_t_textbooks <- textbook_mean - error_t_textbooks
right_t_textbooks <- textbook_mean + error_t_textbooks
```

### Problem #4
Determining the Correct Amount of Samples that need to be taken to achieve range of 5 dollars with 95% confidence
```{r}
marketing_sd <- 12
marketing_ME <- 5
marketing_z_stat <- qnorm(0.975)
n_marketing <- ((marketing_z_stat * marketing_sd) / marketing_ME)^2
```

### Problem #5
```{r}
salary_data <- read.csv("data/2013 ncaa tourney coaches salaries.csv")

# print(head(salary_data))
total_pay <- salary_data$TOTAL.PAY
total_pay_mean <- mean(total_pay)
total_pay_sd <- sd(total_pay)
total_pay_obs <- length(total_pay)

# Normal Distribution for 98% Confidence Intervals
error_tp <- qnorm(0.99) * total_pay_sd / sqrt(total_pay_obs)
left_norm_tp <- total_pay_mean - error_tp
right_norm_tp <- total_pay_mean + error_tp
# T-Distribution for  98% Confidence Intervals
error_t_tp <- qt(0.99, df = total_pay_obs - 1) * total_pay_sd / sqrt(total_pay_obs)
left_t_tp <- total_pay_mean - error_t_tp
right_t_tp <- total_pay_mean + error_t_tp

total_pay_t_test <- t.test(total_pay)

left_norm_tp
right_norm_tp
```

### Problem #5 Part 2 without Mike Krzyzewski data in total pay
```{r}
salary_data <- read.csv("data/2013 ncaa tourney coaches salaries.csv")
# print(head(salary_data))
total_pay <- salary_data$TOTAL.PAY
total_pay <- total_pay[2:length(total_pay)]
total_pay_mean <- mean(total_pay)
total_pay_sd <- sd(total_pay)
total_pay_obs <- length(total_pay)

# Normal Distribution for 98% Confidence Intervals
error_tp <- qnorm(0.99) * total_pay_sd / sqrt(total_pay_obs)
left_norm_tp <- total_pay_mean - error_tp
right_norm_tp <- total_pay_mean + error_tp
# T-Distribution for 98% Confidence Intervals
error_t_tp <- qt(0.99, df = total_pay_obs - 1) * total_pay_sd / sqrt(total_pay_obs)
left_t_tp <- total_pay_mean - error_t_tp
right_t_tp <- total_pay_mean + error_t_tp

total_pay_t_test <- t.test(total_pay)

left_norm_tp
right_norm_tp
```

### Problem #6
```{r}
student_debt <- read_csv("data/student debt North Carolina.csv", col_type = list(.default = col_guess()))
print(student_debt)

us_mean_debt <- 21520
nc_student_debt <- student_debt$`Average debt of graduates`
nc_student_debt

student_debt_t_test <- t.test(nc_student_debt, mu = us_mean_debt, alternative = "less")
student_debt_t_test
```

### Problem #7
```{r}
soda_cans <- read.csv("data/soda cans per week.csv")
soda_can_data <- soda_cans$Ã¯..Cans
big_n <- 28000
soda_can_mean <- mean(soda_can_data)
soda_can_sd <- sd(soda_can_data)
soda_can_obs <- length(soda_can_data)
# Normal Distribution
error_soda <- qnorm(0.995) * soda_can_sd / sqrt(soda_can_obs)
left_norm_soda <- soda_can_mean - error_soda
right_norm_soda <- soda_can_mean + error_soda
left_norm_big_soda <- big_n * left_norm_soda
right_norm_big_soda <- big_n * right_norm_soda
left_norm_big_soda
right_norm_big_soda
```


### Problem #9
```{r}
exhaustion_mean <- 637
exhaustion_sd <- 265
exhaustion_obs <- 24

self_talk_mean <- 750
self_talk_sd <- 265

# Calculating the Actual T Stat
exh_t <- (self_talk_mean - exhaustion_mean) / (exhaustion_sd / sqrt(exhaustion_obs))

# Quantile Function for t-dist
# This is how you get the Error for Confidence Intervals
exh_t_stat <- qt(0.975, df = exhaustion_obs - 1)
# A way to calculate the P-value if a dataset is not given
exh_p_value <- pt(-abs(exh_t), df = exhaustion_obs - 1)
```

### Problem #10
```{r}
raisins <- c(1219, 1214, 1087, 1200, 1419, 1121, 1325, 1345, 1244, 1258, 1356, 1132, 1191, 1270, 1295, 1135)
raisins_mean <- mean(raisins)
raisins_sd <- sd(raisins)
raisins_obs <- length(raisins)

# T-Test for Data set
raisins_t_test <- t.test(raisins, mu = 1200, alternative = "greater")
raisins_t_test
```
